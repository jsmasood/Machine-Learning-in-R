---
title: "ANLY 512 Assignment 2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

####**4.7.6**
<br>

(a). In order to find out the probability we solve for the equation

\[ P(Y) = \frac {e^x} {1 + e^x}  where \\ \\ x = \beta_0 + \beta_1X_1 + \beta_2X_2 \\ \\ \beta_0 = -6, \beta_1 = 0.05, \beta_2 = 1. \]
<br>
For X1 = 40 & X2 = 3.5, P = 0.378
<br>

![Working for this question](Q1.jpg)

(b). In order to have a 50% chance of getting an A the student needs to study 50 hours a week.


```{r 10,  echo=FALSE}





```

####**4.7.10**
<br>

Correlation matrix for "Weekly" dataset:

```{r Weekly, echo=FALSE}
library(ISLR)
library(knitr)


data(Weekly)
head(Weekly)

kable(cor(Weekly[,-9]))

pairs(Weekly)

plot(Weekly$Volume)
plot(Weekly$Year, Weekly$Volume)

```

```{r}

glm_dir_weekly<- glm(Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume, Weekly, family=binomial)
kable(coefficients(summary(glm_dir_weekly)))

# Creating Confusion Matrix

Weekly$pred = predict(glm_dir_weekly, Weekly, type = "response")
Weekly$class_pred = predict(glm_dir_weekly, Weekly, type = "response") > .5

sum(Weekly$class_pred == Weekly$Direction) / nrow(Weekly)

table(Weekly$Direction, Weekly$class_pred)

# (d)

library(dplyr)

Weekly_2 <- filter(Weekly, Year!= 2009 & Year!= 2010)

glm_dir_lag2<- glm(Direction ~ Lag2, Weekly_2, family=binomial)
# kable(coefficients(summary(glm_dir_lag2)))

# Creating Confusion Matrix

Weekly_2$pred = predict(glm_dir_lag2, Weekly_2, type = "response")
Weekly_2$class_pred = predict(glm_dir_lag2, Weekly_2, type = "response") > .5

sum(Weekly_2$class_pred == Weekly_2$Direction) / nrow(Weekly_2)

table(Weekly_2$Direction, Weekly_2$class_pred)

```


####**Extra Problem 25**
<br>

```{r Rnist, echo=FALSE}

library(dplyr)

load("mnist_all.RData")

plot_digit <-function(j){
  arr784 <-as.numeric(train$x[j,])
  col=gray(12:1/12)
  image(matrix(arr784, nrow=28)[,28:1], col=col,
        main =paste("this is a  ",train$y[j]))
  }

# Practice Plotting

plot_digit(14) #6
plot_digit(18) #8
plot_digit(8) #3
plot_digit(1) #5
plot_digit(12) #5

# For each column in the test$x matrix, we calculate the mean and the sd
trainx_colmean<- apply(train$x, 2, mean)
trainx_colsd <- apply(train$x, 2, sd)

plot(trainx_colmean)
plot(trainx_colsd)

# table(trainx_colsd)

# Columns with low variability
sum(trainx_colsd == 0)
# Columns with high variability
sum(trainx_colsd > 110)

# Get column index of highest SD
which(trainx_colsd > 113.8) #It is column number 379

V379 <- cbind(train$x[,379], train$y)
colnames(V379) <- c("V379","Digit")

# Create Master Data Frame
df_V379 <- as.data.frame(V379)
df_V379 <- filter(df_V379, Digit == 3 | Digit == 5)

df_V379$Five[df_V379$Digit == 3] <- 0
df_V379$Five[df_V379$Digit == 5] <- 1

# Run GLM Model

classifier1_train <- glm(Five ~ V379, data = df_V379, family = "binomial")
summary(classifier1_train)

predict1_train <- predict(classifier1_train, data = df_V379, type ="response")
table(df_V379$Digit, predict1_train > 0.5)

# False positives are 1381 in training data (i.e. predicted 5 when the digit was actually 3)
# False positive rate = 1381/1381 + 4750

# Prepare test data frame

df_test <- as.data.frame(test$x)
df_test$Digit <- test$y

df_test <- df_test %>% select(V379, Digit)

df_test <- filter(df_test, Digit == 3 | Digit == 5)

df_test$Five[df_test$Digit == 3] <- 0
df_test$Five[df_test$Digit == 5] <- 1

classifier1_test <- glm(Five ~ V379, data = df_test, family = "binomial")
summary(classifier1_test)

predict1_test <- predict(classifier1_test, data = df_test, type ="response")
table(df_test$Digit, predict1_test > 0.5)

# False positives are 229 in training data (i.e. predicted 5 when the digit was actually 3)
# False positive rate = 229/229+781
  
```


####**Extra Problem 26**

```{r Rnist2, echo=FALSE}

library(ggplot2)
library(pROC)

sd(train$x[,497])
cor(train$x[,379], train$x[,497])

# Prepare training data frame
df_train <- as.data.frame(train$x)
df_train$Digit <- train$y
df_train <- df_train %>% select(V379, V497, Digit)

df_train <- filter(df_train, Digit == 3 | Digit == 5)

df_train$Five[df_train$Digit == 3] <- 0
df_train$Five[df_train$Digit == 5] <- 1

classifier2_train <- glm(Five ~ V379 + V497, data = df_train, family = "binomial")
summary(classifier2_train)

predict2_train <- predict(classifier2_train, data = df_train, type ="response")
table(df_train$Digit, predict2_train > 0.5)

#Produce ROC curve
classifier2_train_roc <- roc(Five ~ predict2_train, data = df_train)
plot(classifier2_train_roc)
classifier2_train_roc[["auc"]]

#Prepare test data frame
df_test <- as.data.frame(train$x)
df_test$Digit <- train$y
df_test <- df_test %>% select(V379, V497, Digit)

df_test <- filter(df_test, Digit == 3 | Digit == 5)

df_test$Five[df_test$Digit == 3] <- 0
df_test$Five[df_test$Digit == 5] <- 1

classifier2_test <- glm(Five ~ V379 + V497, data = df_train, family = "binomial")
summary(classifier2_test)

predict2_test <- predict(classifier2_test, data = df_test, type ="response")
table(df_train$Digit, predict2_test > 0.5)

#Produce ROC curve
classifier2_test_roc <- roc(Five ~ predict2_test, data = df_test)
plot(classifier2_test_roc)
classifier2_test_roc[["auc"]]

ggplot(df_train, aes(V379, V497, color=Five))+ geom_point() 

```

From the graph we can see that for the digits of value "3" (i.e. black in our graph) the points are clumped towards the top right. On the other hand for the value "5" there are more light blue points towards the bottom and the left.

However there is a lot of noise in this graph as well which can explain the high level of false positives in our classification model.

This shows that there is variation for the two numbers in the values of V379 and V497, thought looking at the graph it seems as if V379 is a better classifer among the two.

####**Extra Problem 27**

```{r Rnist3, echo=FALSE}

which(trainx_colsd >= 112.379028356589) #10 highest variances

# Prepare training data frame
df_train <- as.data.frame(train$x)
df_train$Digit <- train$y
df_train <- df_train %>% select(V379, V407, V410, V434, V435, V438, V462, V463, V628, V629, Digit)

df_train <- filter(df_train, Digit == 3 | Digit == 5)

df_train$Five[df_train$Digit == 3] <- 0
df_train$Five[df_train$Digit == 5] <- 1

# Run Logistic Regression

classifier3_train <- glm(Five ~ V379+V407+V410+V434+V435+V438+V462+V463+V628+V629, data = df_train, family = "binomial")
summary(classifier3_train)

predict3_train <- predict(classifier3_train, data = df_train, type ="response")
table(df_train$Digit, predict3_train > 0.5)

#Produce ROC curve
classifier3_train_roc <- roc(Five ~ predict3_train, data = df_train)
plot(classifier3_train_roc)
classifier3_train_roc[["auc"]]

#Prepare test data frame
df_test <- as.data.frame(train$x)
df_test$Digit <- train$y
df_test <- df_test %>% select(V379, V407, V410, V434, V435, V438, V462, V463, V628, V629, Digit)

df_test <- filter(df_test, Digit == 3 | Digit == 5)

df_test$Five[df_test$Digit == 3] <- 0
df_test$Five[df_test$Digit == 5] <- 1

# Run Logistic Regression

classifier3_test <- glm(Five ~ V379+V407+V410+V434+V435+V438+V462+V463+V628+V629, data = df_train, family = "binomial")
summary(classifier3_test)

predict3_test <- predict(classifier3_test, data = df_test, type ="response")
table(df_train$Digit, predict3_test > 0.5)

#Produce ROC curve
classifier3_test_roc <- roc(Five ~ predict3_test, data = df_train)
plot(classifier3_test_roc)
classifier3_test_roc[["auc"]]

```

We see our predictor works well on the test data and the AOC is relatively high. We also see from the regression output that 6 of the 10 variables with the highest variance are significant in predicting the digit. Thus we can say that this method for choosing a classifier has its merits.

We can also explore some alternative methods for choosing a classifier. This involves exploring variables with very low correlation as these would likely be the pixels that are black for one digit and white for another. Another means would be to estimate the range of variables which represent these pixels (for example which columns correspond to the pixels in the top left).

####**Extra Problem 23**

```{r}

library(ISLR)
library(pROC)
data(OJ)
head(OJ)

OJ$purchase01[which(OJ$Purchase == "CH")] <- 0
OJ$purchase01[which(OJ$Purchase == "MM")] <- 1

OJ <- OJ[,-1]

fit.22a <- glm(purchase01 ~., data= OJ, family = binomial)
summary(fit.22a)

OJ2 <- OJ[,-c(10, 11, 12, 16, 17)]

fit.22b <- glm(purchase01 ~., data= OJ2, family = binomial)
summary(fit.22b)

fit.22c<- glm(purchase01 ~ PriceCH+PriceMM+DiscMM+LoyalCH+PctDiscMM, data= OJ2, family = binomial)
summary(fit.22c)

OJ$pred = predict(fit.22c, OJ, type = "response")

# OJ$class_pred = predict(fit.22c, OJ, type = "response") > .5

roc_fit22c <- roc(OJ$purchase01, OJ$pred)
plot(roc_fit22c)
auc(roc_fit22c)

```